from storages.backends.s3boto3 import S3Boto3Storage
from django.conf import settings
import os
import logging

logger = logging.getLogger(__name__)


class MediaStorage(S3Boto3Storage):
    """
    Stockage pour les fichiers m√©dias (images, vid√©os, documents upload√©s par les utilisateurs).
    Les URLs sont sign√©es (querystring_auth=True) pour un acc√®s s√©curis√©.
    """
    location = 'media'  # Dossier racine dans votre bucket S3 pour les m√©dias
    file_overwrite = False  # Ne pas √©craser les fichiers existants par d√©faut
    default_acl = 'private'  # Fichiers priv√©s par d√©faut (n√©cessite URLs sign√©es)
    bucket_name = settings.AWS_STORAGE_BUCKET_NAME
    region_name = settings.AWS_S3_REGION_NAME
    custom_domain = settings.AWS_S3_CUSTOM_DOMAIN
    querystring_auth = True  # G√©n√®re des URLs sign√©es (URLs temporaires et s√©curis√©es)
    object_parameters = settings.AWS_S3_OBJECT_PARAMETERS
    access_key = settings.AWS_ACCESS_KEY_ID
    secret_key = settings.AWS_SECRET_ACCESS_KEY
    auto_create_bucket = False  # Ne pas cr√©er automatiquement (s√©curit√©)
    auto_create_acl = False  # Ne pas cr√©er automatiquement les ACL
    
    def save(self, name, content, max_length=None):
        """Surcharge pour ajouter des logs lors de l'upload"""
        if settings.DEBUG:
            print(f"üì§ Upload vers S3: {name} (bucket: {self.bucket_name})")
        try:
            result = super().save(name, content, max_length)
            if settings.DEBUG:
                print(f"‚úÖ Upload r√©ussi vers S3: {result}")
            return result
        except Exception as e:
            if settings.DEBUG:
                print(f"‚ùå Erreur lors de l'upload vers S3: {e}")
            raise


class StaticStorage(S3Boto3Storage):
    """
    Stockage pour les fichiers statiques (CSS, JavaScript, images de l'application).
    Ces fichiers sont g√©n√©ralement publics et n'ont pas besoin d'URLs sign√©es.
    Note: Ce projet utilise WhiteNoise pour les fichiers statiques, cette classe est fournie pour r√©f√©rence.
    """
    location = 'static'  # Dossier racine dans votre bucket S3 pour les statiques
    file_overwrite = True  # √âcrase les fichiers statiques existants
    default_acl = 'public-read'  # Rend les fichiers statiques publiquement lisibles
    bucket_name = settings.AWS_STORAGE_BUCKET_NAME
    region_name = settings.AWS_S3_REGION_NAME
    custom_domain = settings.AWS_S3_CUSTOM_DOMAIN
    querystring_auth = False  # Pas besoin d'URLs sign√©es pour les fichiers statiques
    object_parameters = settings.AWS_S3_OBJECT_PARAMETERS
    access_key = settings.AWS_ACCESS_KEY_ID
    secret_key = settings.AWS_SECRET_ACCESS_KEY
    auto_create_bucket = True
    auto_create_acl = True


class ProductImageStorage(S3Boto3Storage):
    """
    Stockage sp√©cifique pour les images de produits.
    Les images de produits peuvent n√©cessiter une gestion unique des noms de fichiers
    pour √©viter les conflits et sont g√©n√©ralement des m√©dias (acc√®s s√©curis√©).
    """
    location = 'media/products'  # Sous-dossier sp√©cifique pour les images de produits
    file_overwrite = False
    default_acl = None
    bucket_name = settings.AWS_STORAGE_BUCKET_NAME
    region_name = settings.AWS_S3_REGION_NAME
    custom_domain = settings.AWS_S3_CUSTOM_DOMAIN
    querystring_auth = True
    object_parameters = settings.AWS_S3_OBJECT_PARAMETERS
    access_key = settings.AWS_ACCESS_KEY_ID
    secret_key = settings.AWS_SECRET_ACCESS_KEY
    auto_create_bucket = True
    auto_create_acl = True

    def _generate_unique_filename(self, filename):
        """G√©n√®re un nom de fichier unique en ajoutant un compteur si n√©cessaire."""
        name_parts = filename.rsplit('.', 1)
        base_name = name_parts[0]
        extension = name_parts[1] if len(name_parts) > 1 else ''
        counter = 1
        while self.exists(os.path.join(self.location, f"{base_name}_{counter}.{extension}")):
            counter += 1
        return os.path.join(self.location, f"{base_name}_{counter}.{extension}")

    def get_available_name(self, name, max_length=None):
        """Surcharge pour g√©rer les noms de fichiers uniques avant de les enregistrer."""
        # Retire le pr√©fixe de la localisation pour v√©rifier l'existence dans le bon format
        relative_path = os.path.relpath(name, self.location) if name.startswith(self.location) else name
        if self.exists(os.path.join(self.location, relative_path)):
            return self._generate_unique_filename(relative_path)
        return name


class HeroImageStorage(S3Boto3Storage):
    """
    Stockage sp√©cifique pour les images du "hero" (banni√®re principale).
    Ces images peuvent √™tre √©cras√©es et sont souvent publiques.
    """
    location = 'media/hero'  # Sous-dossier sp√©cifique pour les images hero
    file_overwrite = True  # On autorise l'√©crasement pour les images hero
    default_acl = None  # Utilise les param√®tres de bucket par d√©faut
    bucket_name = settings.AWS_STORAGE_BUCKET_NAME
    region_name = settings.AWS_S3_REGION_NAME
    custom_domain = settings.AWS_S3_CUSTOM_DOMAIN
    querystring_auth = False  # Pas besoin d'authentification pour les images hero
    object_parameters = {
        'CacheControl': 'max-age=86400',  # Cache d'un jour
    }
    access_key = settings.AWS_ACCESS_KEY_ID
    secret_key = settings.AWS_SECRET_ACCESS_KEY
    auto_create_bucket = True
    auto_create_acl = False  # D√©sactive la cr√©ation automatique des ACLs

